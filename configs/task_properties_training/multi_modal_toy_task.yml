# This is the main config file for default parameters for all hyperparameter and task parameter.
# Every config file should import this. The project will run with these parameters, no matter what.

name: "SLURM"   # MUST BE "SLURM"

# Required
partition: "gpu"
job-name: "lts_gns"    # this will be the experiments name in slurm

# Required - Cluster Specific
num_parallel_jobs: 99
ntasks: 1
cpus-per-task: 2
mem-per-cpu: 15000
time: 2880  # in minutes

sbatch_args: # Dictionary of SBATCH keywords and arguments
  gres: "gpu:1"

slurm_log: "./output/slurmlog" # optional. dir in which slurm output and error logs will be saved.
---
name: p3101_task_properties_multi_modal_toy_task_with_fourier_embedding

import_path: ../default.yml
import_exp: DEFAULT

repetitions: 2 # number of times one set of parameters is run
reps_per_job: 1 # number of repetitions in each job. useful for paralellization. defaults to 1.
reps_in_parallel: 1 # number of repetitions in each job that are executed in parallel. defaults to 1.

iterations: 2000 # number of iterations of the algorithm, usually about 500 when it starts overfitting

params:
  recording:
    wandb:
      enabled: True  # right now disabled to not spam runs during debugging

  device: cuda

  algorithm:
    name: lts_gns
    common:
      evaluation:
        large:
          multi_step_evaluations: []
          animation_task_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   # which tasks to plot.

    lts_gns:
      evaluation:
        large:
          num_posterior_learner_steps: 200
          training_gmm_indices: [0, 8, 16, 24, 32]

      simulator:
        decoder:
          z_embedding: fourier  # whether to embed the z into the hidden dimension of the decoder or not

      posterior_learner:
        name: task_properties_learner

  env:
    name: multi_modal_toy_task