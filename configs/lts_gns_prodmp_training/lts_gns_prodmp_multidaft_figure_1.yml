# This is the main config file for default parameters for all hyperparameter and task parameter.
# Every config file should import this. The project will run with these parameters, no matter what.

name: "SLURM"   # MUST BE "SLURM"

# Required
partition: "gpu"
job-name: "lts_gns_prodmp"    # this will be the experiments name in slurm

# Required - Cluster Specific
num_parallel_jobs: 99
ntasks: 1
cpus-per-task: 2
mem-per-cpu: 15000
time: 2880  # in minutes

sbatch_args: # Dictionary of SBATCH keywords and arguments
  gres: "gpu:1"


slurm_log: "./output/slurmlog" # optional. dir in which slurm output and error logs will be saved.
---
name: p5226_lts_gns_prodmp_figure_1

import_path: ../default.yml
import_exp: DEFAULT

repetitions: 1 # number of times one set of parameters is run
reps_per_job: 1 # number of repetitions in each job. useful for paralellization. defaults to 1.
reps_in_parallel: 1 # number of repetitions in each job that are executed in parallel. defaults to 1.

iterations: 1000 # number of iterations of the algorithm, usually about 500 when it starts overfitting

params:
  recording:
    wandb:
      enabled: True  # right now disabled to not spam runs during debugging

  device: cuda

  algorithm:
    name: lts_gns_prodmp
    common:
      training:
        batches_per_epoch: 500
        # how may minibatches per recorded step. After every epoch, there is the small evaluation of the val tasks.
      evaluation:
        large:
          frequency: 50
          multi_step_evaluations: [1, 5, 10]
          animation_task_indices: [0, 5, 11]   # which tasks to plot.
          recompute_edges: True
          initial_eval: True
      simulator:
        loss: mse
        chamfer:
          density_aware: True

    lts_gns_prodmp:
      evaluation:
        small:
          num_posterior_learner_step: 10
        large:
          num_posterior_learner_steps: 100
          training_gmm_indices: [ ]
          num_z_samples_per_animation_task: 1
      simulator:
        decoder:
          velocity_decoder: False
        likelihood:
          std: 0.01
          chamfer_std: 0.1
      posterior_learner:
        name: multi_daft_posterior_learner
        multi_daft_posterior_learner:
          sample_at_mean: False
          n_components: 3
          d_z: 1

  env:
    name: deformable_plate
    common:
      preprocess:
        train_label_noise: 0.0
        include_pc2mesh: False
        use_collider_velocities: True
      debug:
        max_tasks_per_split: null
    deformable_plate:
      preprocess:
        use_point_cloud: False
      postprocess:
        batch:
          use_adaptive_batch_size: True
          max_eval_batch_size: 1
          max_train_batch_size: 10
          adaptive_batch_size:
            batch_cost: 120



